# =============================================================================
# International News AI Deep Report System - Environment Configuration
# =============================================================================
# Copy this file to `.env` and fill in your values.

# =============================================================================
# Application
# =============================================================================
APP_NAME=NewsDepthSystem
DEBUG=false

# =============================================================================
# Database
# =============================================================================
# SQLite database file path (relative or absolute)
DATABASE_URL=sqlite:///news_depth.db

# =============================================================================
# LLM Configuration (CRITICAL CONSTRAINTS)
# =============================================================================
#
# IMPORTANT: This system is designed to work with a SINGLE 72B model instance.
# All LLM calls must go through an OpenAI-compatible API endpoint.
#
# Constraints:
#   - Only ONE concurrent request to the 72B model
#   - Model is used ONLY for:
#       * Report generation
#       * Multi-perspective synthesis
#       * Controversy summarization
#   - Model is NOT used for:
#       * Crawling
#       * Embedding (use separate small model)
#       * Classification (use rules or small models)
#       * Clustering
#       * Sentiment analysis (use rules or small models)
#

# OpenAI-compatible API endpoint for your 72B model
# Examples:
#   - Local vLLM server: http://localhost:8000/v1
#   - Local Ollama: http://localhost:11434/v1
#   - Cloud API: https://api.openai.com/v1
LLM_API_BASE=http://localhost:8000/v1

# API key (may be dummy for local models, required for cloud APIs)
LLM_API_KEY=sk-dummy

# Model name (must match the model exposed by your API server)
# Examples: Qwen-72B-Chat, Llama-2-70b-chat, mistralai/Mixtral-8x7B-Instruct-v0.1
LLM_MODEL_NAME=Qwen-72B-Chat

# Maximum concurrent requests to LLM (MUST be 1 for 72B model constraint)
LLM_MAX_CONCURRENT=1

# Request timeout in seconds (adjust based on your model and hardware)
LLM_TIMEOUT=300

# =============================================================================
# Embedding Configuration (Separate from LLM)
# =============================================================================
# Use a small, fast model for embeddings (NOT the 72B model)
# Examples: text-embedding-3-small, text-embedding-ada-002, all-MiniLM-L6-v2

# If using OpenAI for embeddings (can be same as LLM if using OpenAI API)
EMBEDDING_API_BASE=https://api.openai.com/v1
EMBEDDING_API_KEY=your_openai_api_key_here
EMBEDDING_MODEL=text-embedding-3-small

# Embedding dimensions (must match your model)
EMBEDDING_DIM=1536

# =============================================================================
# Crawler Configuration
# =============================================================================
# User agent for HTTP requests
CRAWLER_USER_AGENT=NewsDepthSystem/0.1 (+https://github.com/newsdepth)

# Concurrent crawler threads (NOT for LLM)
CRAWLER_CONCURRENT_LIMIT=10

# Request timeout in milliseconds
CRAWLER_REQUEST_TIMEOUT_MS=30000

# Respect robots.txt
CRAWLER_RESPECT_ROBOTS_TXT=true

# Rate limiting: requests per second per domain
CRAWLER_RATE_LIMIT=1.0

# Retry configuration
CRAWLER_MAX_RETRIES=3
CRAWLER_RETRY_DELAY_MS=1000

# =============================================================================
# Content Processing
# =============================================================================
# Chunk size for text splitting (characters)
CHUNK_SIZE=1000

# Chunk overlap (characters)
CHUNK_OVERLAP=200

# Minimum chunk size (characters)
CHUNK_MIN_SIZE=100

# =============================================================================
# Vector Store Configuration
# =============================================================================
# Vector store type: 'sqlite' or 'faiss'
VECTOR_STORE_TYPE=sqlite

# FAISS index path (only if using FAISS)
# FAISS_INDEX_PATH=./data/faiss_index

# =============================================================================
# Scheduler Configuration
# =============================================================================
# Cron expressions for scheduled tasks
# Format: second minute hour day month dow year
# Sitemap update: daily at 2 AM
SITEMAP_UPDATE_CRON=0 0 2 * * * *

# Keyword search: every 6 hours
KEYWORD_SEARCH_CRON=0 0 */6 * * * *

# =============================================================================
# Report Generation
# =============================================================================
# Maximum chunks to retrieve for report generation
REPORT_MAX_CHUNKS=200

# Maximum tokens in generated report
REPORT_MAX_TOKENS=8000

# Temperature for report generation (lower = more factual)
REPORT_TEMPERATURE=0.3

# =============================================================================
# API Configuration (Optional FastAPI)
# =============================================================================
API_ENABLED=false
API_HOST=127.0.0.1
API_PORT=8080

# =============================================================================
# Logging
# =============================================================================
LOG_LEVEL=INFO
# LOG_FILE=./logs/newsdepth.log
